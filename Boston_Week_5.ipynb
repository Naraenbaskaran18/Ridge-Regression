{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0hsmyrHzHXKuHu/kpTa2+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naraenbaskaran18/Ridge-Regression/blob/main/Boston_Week_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "h-9cgZHqSuKh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RidgeRegression:\n",
        "    def __init__(self, alpha=1):\n",
        "        self.alpha = alpha\n",
        "        self.theta = None\n",
        "        \n",
        "    def cost_function(self, X, y, theta):\n",
        "        m = len(y) \n",
        "        y_pred = X.dot(theta)\n",
        "        cost = (1/(2*m)) * np.sum((y_pred - y)**2) + (self.alpha/(2*m)) * np.sum(theta[1:]**2)\n",
        "        return cost\n",
        "    \n",
        "    def gradient_function(self, X, y, theta):\n",
        "        m = len(y)\n",
        "        y_pred = X.dot(theta)\n",
        "        grad = (1/m) * (X.T.dot(y_pred - y)) + (self.alpha/m) * np.concatenate(([0], theta[1:]))\n",
        "        return grad\n",
        "    \n",
        "    def fit(self, X, y, learning_rate=0.01, num_iterations=1000):\n",
        "        m, n = X.shape\n",
        "        X = np.concatenate((np.ones((m, 1)), X), axis=1)\n",
        "        self.theta = np.zeros(n+1)\n",
        "        \n",
        "        for i in range(num_iterations):\n",
        "            grad = self.gradient_function(X, y, self.theta)\n",
        "            self.theta = self.theta - learning_rate * grad\n",
        "            \n",
        "    def predict(self, X):\n",
        "        m = X.shape[0]\n",
        "        X = np.concatenate((np.ones((m, 1)), X), axis=1)\n",
        "        return X.dot(self.theta)\n",
        "    \n",
        "    def grid_search(self, X_train, y_train, X_test, y_test, alpha_values, learning_rate_values, num_iterations_values):\n",
        "        best_alpha = None\n",
        "        best_learning_rate = None\n",
        "        best_num_iterations = None\n",
        "        best_r2 = -np.inf\n",
        "        \n",
        "        for alpha in alpha_values:\n",
        "            for learning_rate in learning_rate_values:\n",
        "                for num_iterations in num_iterations_values:\n",
        "                    self.alpha = alpha\n",
        "                    self.fit(X_train, y_train, learning_rate=learning_rate, num_iterations=num_iterations)\n",
        "                    y_pred = self.predict(X_test)\n",
        "                    r2 = r2_score(y_test, y_pred)\n",
        "                    if r2 > best_r2:\n",
        "                        best_r2 = r2\n",
        "                        best_alpha = alpha\n",
        "                        best_learning_rate = learning_rate\n",
        "                        best_num_iterations = num_iterations\n",
        "        \n",
        "        self.alpha = best_alpha\n",
        "        self.fit(X_train, y_train, learning_rate=best_learning_rate, num_iterations=best_num_iterations)\n",
        "        print(\"Best hyperparameters:\")\n",
        "        print(\"alpha:\", best_alpha)\n",
        "        print(\"learning rate:\", best_learning_rate)\n",
        "        print(\"num iterations:\", best_num_iterations)\n",
        "        print(\"best R2 score:\", best_r2)"
      ],
      "metadata": {
        "id": "ASsL91M1XsDB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the Boston Housing dataset\n",
        "boston = fetch_openml(name='boston')\n",
        "X, y = boston.data, boston.target\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# split the dataset into training and test sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KqvCpKJSwYB",
        "outputId": "3bc2cd15-d42b-4104-c4bc-0642ed43f4c7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/datasets/_openml.py:292: UserWarning: Multiple active versions of the dataset matching the name boston exist. Versions may be fundamentally different, returning version 1.\n",
            "  warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create an instance of the RidgeRegression class\n",
        "ridge_reg = RidgeRegression()\n",
        "\n"
      ],
      "metadata": {
        "id": "jCfCjup4S0jp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameters to search over\n",
        "alpha_values = [0.01, 0.1, 1, 10]\n",
        "learning_rate_values = [0.001, 0.01,0.1]\n",
        "num_iterations_values = [100,1000,10000]"
      ],
      "metadata": {
        "id": "EiL6HxVuTAra"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform grid search to find the best hyperparameters\n",
        "ridge_reg.grid_search(X_train, y_train, X_test, y_test, alpha_values, learning_rate_values, num_iterations_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65_AxD2YTGYn",
        "outputId": "91aacfb9-72f3-4323-e3ce-2f47f96a92c7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:\n",
            "alpha: 0.01\n",
            "learning rate: 0.1\n",
            "num iterations: 10000\n",
            "best R2 score: 0.6687562987931833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions on the test data\n",
        "y_pred = ridge_reg.predict(X_test)\n",
        "\n",
        "# compute the R2 score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R2 score on test set:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Alsf3IuKTJAa",
        "outputId": "1650f611-2812-4340-eb6e-a5d6d478b0c9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 score on test set: 0.6687591740646741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the mse\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"mse:\", mse)"
      ],
      "metadata": {
        "id": "5dWu930-TM-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe47013-c0ba-4ac8-a15f-9ed5ceacc656"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mse: 24.291142902987474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ksnEIgsrXmyu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}